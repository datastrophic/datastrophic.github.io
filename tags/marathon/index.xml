<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Marathon on datastrophic</title><link>https://datastrophic.io/tags/marathon/</link><description>Recent content in Marathon on datastrophic</description><generator>Hugo</generator><language>en</language><copyright>Â© 2025 datastrophic</copyright><lastBuildDate>Thu, 12 Oct 2017 00:00:00 +0000</lastBuildDate><atom:link href="https://datastrophic.io/tags/marathon/index.xml" rel="self" type="application/rss+xml"/><item><title>Spark JobServer: from Spark Standalone to Mesos, Marathon and Docker</title><link>https://datastrophic.io/spark-jobserver-from-spark-standalone-to-mesos-marathon-and-docker-part-i/</link><pubDate>Thu, 12 Oct 2017 00:00:00 +0000</pubDate><guid>https://datastrophic.io/spark-jobserver-from-spark-standalone-to-mesos-marathon-and-docker-part-i/</guid><description>After several years of running Spark JobServer workloads, the need for better availability and multi-tenancy emerged across several projects author was involved in. This blog post covers design decisions made to provide higher availability and fault tolerance of JobServer installations, multi-tenancy for Spark workloads, scalability and failure recovery automation, and software choices made in order to reach these goals. Spark JobServer Spark JobServer is widely used across a variety of reporting and aggregating systems.</description></item></channel></rss>